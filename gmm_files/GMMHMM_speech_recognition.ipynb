{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GMMHMM Speech Recognition\n",
    "\n",
    "Nathan Singer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import MFCC\n",
    "import gmmhmm\n",
    "import gmm\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.io.wavfile\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Problem$ $1$\n",
    "\n",
    "Write a function which accepts a GMMHMM in the format above as well as an integer n sim, and which simulates the GMMHMM process, generating n sim different observations. Do so by implementing the following function declaration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "        1, 1, 1, 1, 1, 0, 0]),\n",
       " array([[  5.30750179,  19.82050748,  -3.60695663],\n",
       "        [  2.00322773,  17.64181724,  -4.86349831],\n",
       "        [ -1.02872203,  20.14948984,  -6.4499947 ],\n",
       "        [ 14.25833238, -34.35404652,  -1.30278812],\n",
       "        [-11.00810416,  -1.29764062,  17.48424448],\n",
       "        [-14.91596317,  -3.67673371,  18.03766742],\n",
       "        [ 13.89690218, -32.81023017,   1.03215793],\n",
       "        [ 16.96149059, -33.51240129,  -1.62954088],\n",
       "        [ -1.5479285 ,  15.67259739,  -4.5801316 ],\n",
       "        [-13.29720993,  -1.34532731,  13.24874083],\n",
       "        [ 17.0510294 , -31.74439625,  -0.40921311],\n",
       "        [ -8.36143786,   4.41021274,  20.89299476],\n",
       "        [ 14.49082789, -33.03551785,  -2.31755267],\n",
       "        [ 14.97867353, -33.97507156,  -2.79786902],\n",
       "        [ -9.44098852,  -2.83870891,  12.71748398],\n",
       "        [ -2.5438008 ,  14.61001039,  -1.8716613 ],\n",
       "        [  2.48281866,  17.08865886,  -1.18759445],\n",
       "        [ -0.9518281 ,  18.99067921,  -0.3108774 ],\n",
       "        [ -3.24809684,  23.55630478,  -0.65696132],\n",
       "        [ 16.45492714, -31.8955727 ,  -1.60144716],\n",
       "        [-14.33355058,   1.12328527,  14.58367204],\n",
       "        [ 14.80219232, -33.17525936,  -2.07646468],\n",
       "        [  0.92458424,  16.52895489,  -6.81517953],\n",
       "        [ -9.77422044,  -0.15662613,  10.81516428],\n",
       "        [-13.14679094,   0.21761566,  11.23221115],\n",
       "        [ 14.92646195, -33.89104767,  -2.72345233],\n",
       "        [-10.55582917,  -0.16568048,  16.16283892],\n",
       "        [ 16.81102979, -31.83066992,  -1.4885011 ],\n",
       "        [ -0.30437481,  16.03677996,  -2.77994527],\n",
       "        [  0.49802718,  17.81778491,  -2.99393036]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def sample_gmmhmm(gmmhmm, n_sim = 30):\n",
    "    \"\"\"\n",
    "    Simulate sampling from a GMMHMM.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    states : ndarray of shape (n_sim,)\n",
    "    The sequence of states\n",
    "    obs : ndarray of shape (n_sim, K)\n",
    "    The generated observations (column vectors of length K)\n",
    "    \"\"\"\n",
    "    A = gmmhmm[0]\n",
    "    weights = gmmhmm[1]\n",
    "    means = gmmhmm[2]\n",
    "    covars = gmmhmm[3]\n",
    "    pi = gmmhmm[4]\n",
    "    \n",
    "    samples = []\n",
    "    states = []\n",
    "    \n",
    "    #Do first state here using pi\n",
    "    state = np.argmax(np.random.multinomial(1, pi)) \n",
    "    sample_component = np.argmax(np.random.multinomial(state, weights[1,:]))\n",
    "    \n",
    "    samples.append(np.random.multivariate_normal(means[state, sample_component, :], covars[state, sample_component, :, :]))\n",
    "    states.append(state)\n",
    "    \n",
    "    #Iterate through each sample\n",
    "    for _ in xrange(1, n_sim):\n",
    "        state = np.argmax(np.random.multinomial(1, A[state]))\n",
    "        sample_component = np.argmax(np.random.multinomial(state, weights[1,:]))\n",
    "        \n",
    "        samples.append(np.random.multivariate_normal(means[state, sample_component, :], covars[state, sample_component, :, :]))\n",
    "        states.append(state)\n",
    "        \n",
    "    return np.array(states), np.array(samples)\n",
    "    \n",
    "    return states, obs\n",
    "\n",
    "A = np.array([[.65, .35], [.15, .85]])\n",
    "pi = np.array([.8, .2])\n",
    "weights = np.array([[.7, .2, .1], [.1, .5, .4]])\n",
    "means1 = np.array([[0., 17., -4.], [5., -12., -8.], [-16., 22., 2.]])\n",
    "means2 = np.array([[-5., 3., 23.], [-12., -2., 14.], [15., -32., 0.]])\n",
    "means = np.array([means1, means2])\n",
    "covars1 = np.array([5*np.eye(3), 7*np.eye(3), np.eye(3)])\n",
    "covars2 = np.array([10*np.eye(3), 3*np.eye(3), 4*np.eye(3)])\n",
    "covars = np.array([covars1, covars2])\n",
    "gmmhmm = [A,weights,means,covars,pi]\n",
    "\n",
    "sample_gmmhmm(gmmhmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Problem$ $2$\n",
    "\n",
    "Create a list of MFCC's for each of the wav files. You should end with 5 lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def problem2():\n",
    "    \n",
    "    num_wav_files = 155\n",
    "    num_each = 31\n",
    "\n",
    "    biology_files = []\n",
    "    stats_files = []\n",
    "    polysci_files = []\n",
    "    psych_files = []\n",
    "    math_files = []\n",
    "\n",
    "    def get_files():\n",
    "\n",
    "        for k in xrange(1,num_each): #exclude first one because it's all of them together\n",
    "            biology_files.append(scipy.io.wavfile.read('Biology ({}).wav'.format(k)))\n",
    "            stats_files.append(scipy.io.wavfile.read('Statistics ({}).wav'.format(k)))\n",
    "            polysci_files.append(scipy.io.wavfile.read('PoliticalScience ({}).wav'.format(k)))\n",
    "            psych_files.append(scipy.io.wavfile.read('Psychology ({}).wav'.format(k)))\n",
    "            math_files.append(scipy.io.wavfile.read('Mathematics ({}).wav'.format(k)))\n",
    "\n",
    "    get_files()\n",
    "\n",
    "    bio_mfcc = []\n",
    "    stats_mfcc = []\n",
    "    polysci_mfcc = []\n",
    "    psych_mfcc = []\n",
    "    math_mfcc = []\n",
    "\n",
    "    def get_mfccs():\n",
    "\n",
    "        for i in xrange(num_each-1):\n",
    "            bio_mfcc.append(MFCC.extract(biology_files[i][1]))\n",
    "            stats_mfcc.append(MFCC.extract(stats_files[i][1]))\n",
    "            polysci_mfcc.append(MFCC.extract(polysci_files[i][1]))\n",
    "            psych_mfcc.append(MFCC.extract(psych_files[i][1]))\n",
    "            math_mfcc.append(MFCC.extract(math_files[i][1]))\n",
    "\n",
    "        return bio_mfcc, stats_mfcc, polysci_mfcc, psych_mfcc, math_mfcc \n",
    "\n",
    "    return get_mfccs()\n",
    "\n",
    "#problem2()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Problem$ $3$\n",
    "\n",
    "Partition each list of MFCCs into a training set of 20 samples, and a test set of the remaining 10 samples.\n",
    "Using the training sets, train a GMMHMM on each of the words from the previous problem with at least 10 random restarts, keeping the best model for each word (the one with the highest log-likelihood). This process may take several minutes. Since you will not want to run this more than once, you will want to save the best model for each word to disk using the pickle module so that you can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAACfCAYAAADtYvKbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x103d0b050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bio20 = problem2()[0][:20]\n",
    "bio10 = problem2()[0][20:]\n",
    "stats20 = problem2()[1][:20]\n",
    "stats10 = problem2()[1][20:]\n",
    "ps20 = problem2()[2][:20]\n",
    "ps10 = problem2()[2][20:]\n",
    "psych20 = problem2()[3][:20]\n",
    "psych10 = problem2()[3][20:]\n",
    "math20 = problem2()[4][:20]\n",
    "math10 = problem2()[4][20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't know why the above graph came out or what it means, but hey, it sure looks cool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMMHMM(cvtype='diag',\n",
      "    gmms=[GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3)],\n",
      "    n_components=5, n_mix=3,\n",
      "    startprob=array([  1.11027e-17,   1.11027e-17,   1.11306e-17,   5.36448e-01,\n",
      "         4.63552e-01]),\n",
      "    startprob_prior=1.0,\n",
      "    transmat=array([[  9.65227e-01,   1.96177e-02,   5.08545e-03,   1.00701e-02,\n",
      "          2.22045e-16],\n",
      "       [  2.24896e-16,   9.42835e-01,   5.71651e-02,   2.22045e-16,\n",
      "          2.22045e-16],\n",
      "       [  2.91681e-02,   4.36556e-02,   8.72171e-01,   5.14423e-02,\n",
      "          3.56276e-03],\n",
      "       [  6.09821e-03,   2.36536e-03,   1.91216e-02,   9.32913e-01,\n",
      "          3.95015e-02],\n",
      "       [  2.24720e-16,   2.22045e-16,   4.71248e-03,   6.32182e-02,\n",
      "          9.32069e-01]]),\n",
      "    transmat_prior=1.0, var=3)\n",
      "GMMHMM(cvtype='diag',\n",
      "    gmms=[GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3)],\n",
      "    n_components=5, n_mix=3,\n",
      "    startprob=array([  4.99779e-02,   1.00000e-01,   1.84038e-01,   1.11027e-17,\n",
      "         6.65983e-01]),\n",
      "    startprob_prior=1.0,\n",
      "    transmat=array([[ 0.85779,  0.02328,  0.00262,  0.1075 ,  0.00881],\n",
      "       [ 0.04662,  0.8624 ,  0.00115,  0.08712,  0.00271],\n",
      "       [ 0.00197,  0.00366,  0.77484,  0.07503,  0.1445 ],\n",
      "       [ 0.02747,  0.09469,  0.04811,  0.81458,  0.01515],\n",
      "       [ 0.00192,  0.00123,  0.08607,  0.01279,  0.89799]]),\n",
      "    transmat_prior=1.0, var=3)\n",
      "GMMHMM(cvtype='diag',\n",
      "    gmms=[GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3)],\n",
      "    n_components=5, n_mix=3,\n",
      "    startprob=array([  1.11027e-17,   1.11027e-17,   1.11027e-17,   1.00000e+00,\n",
      "         1.11027e-17]),\n",
      "    startprob_prior=1.0,\n",
      "    transmat=array([[  8.41063e-01,   6.71039e-02,   2.24026e-16,   2.22045e-16,\n",
      "          9.18328e-02],\n",
      "       [  4.01213e-02,   8.37642e-01,   3.77652e-02,   4.30581e-02,\n",
      "          4.14137e-02],\n",
      "       [  2.28524e-16,   1.23925e-01,   8.73759e-01,   2.22045e-16,\n",
      "          2.31592e-03],\n",
      "       [  2.22146e-16,   2.20772e-02,   2.49302e-16,   9.77923e-01,\n",
      "          2.22057e-16],\n",
      "       [  3.05552e-02,   4.38461e-03,   8.96524e-02,   2.22045e-16,\n",
      "          8.75408e-01]]),\n",
      "    transmat_prior=1.0, var=3)\n",
      "GMMHMM(cvtype='diag',\n",
      "    gmms=[GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3)],\n",
      "    n_components=5, n_mix=3,\n",
      "    startprob=array([  1.11027e-17,   2.52599e-01,   1.11027e-17,   1.38330e-17,\n",
      "         7.47401e-01]),\n",
      "    startprob_prior=1.0,\n",
      "    transmat=array([[  8.56525e-01,   2.26245e-16,   5.36872e-16,   1.43475e-01,\n",
      "          2.22130e-16],\n",
      "       [  2.22122e-16,   8.58560e-01,   5.61753e-03,   2.96333e-02,\n",
      "          1.06189e-01],\n",
      "       [  1.16352e-02,   1.13835e-03,   9.47167e-01,   3.89233e-02,\n",
      "          1.13647e-03],\n",
      "       [  5.17707e-02,   7.72370e-03,   4.39801e-02,   8.66112e-01,\n",
      "          3.04132e-02],\n",
      "       [  2.22058e-16,   1.09134e-01,   1.31901e-03,   8.77118e-03,\n",
      "          8.80776e-01]]),\n",
      "    transmat_prior=1.0, var=3)\n",
      "GMMHMM(cvtype='diag',\n",
      "    gmms=[GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3)],\n",
      "    n_components=5, n_mix=3,\n",
      "    startprob=array([  1.11027e-17,   1.12096e-17,   9.33576e-01,   1.11027e-17,\n",
      "         6.64243e-02]),\n",
      "    startprob_prior=1.0,\n",
      "    transmat=array([[  8.46855e-01,   1.42227e-01,   2.22045e-16,   1.09186e-02,\n",
      "          5.19040e-16],\n",
      "       [  2.82240e-02,   9.14755e-01,   1.26358e-02,   1.85405e-02,\n",
      "          2.58446e-02],\n",
      "       [  6.27129e-03,   1.86167e-02,   9.66666e-01,   2.28537e-16,\n",
      "          8.44647e-03],\n",
      "       [  1.34602e-02,   8.03662e-03,   2.22048e-16,   9.02935e-01,\n",
      "          7.55682e-02],\n",
      "       [  2.27236e-16,   2.31434e-02,   9.19566e-02,   3.09039e-02,\n",
      "          8.53996e-01]]),\n",
      "    transmat_prior=1.0, var=3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[GMMHMM(cvtype='diag',\n",
       "     gmms=[GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3)],\n",
       "     n_components=5, n_mix=3,\n",
       "     startprob=array([  1.11027e-17,   1.11027e-17,   1.11306e-17,   5.36448e-01,\n",
       "          4.63552e-01]),\n",
       "     startprob_prior=1.0,\n",
       "     transmat=array([[  9.65227e-01,   1.96177e-02,   5.08545e-03,   1.00701e-02,\n",
       "           2.22045e-16],\n",
       "        [  2.24896e-16,   9.42835e-01,   5.71651e-02,   2.22045e-16,\n",
       "           2.22045e-16],\n",
       "        [  2.91681e-02,   4.36556e-02,   8.72171e-01,   5.14423e-02,\n",
       "           3.56276e-03],\n",
       "        [  6.09821e-03,   2.36536e-03,   1.91216e-02,   9.32913e-01,\n",
       "           3.95015e-02],\n",
       "        [  2.24720e-16,   2.22045e-16,   4.71248e-03,   6.32182e-02,\n",
       "           9.32069e-01]]),\n",
       "     transmat_prior=1.0, var=3), GMMHMM(cvtype='diag',\n",
       "     gmms=[GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3)],\n",
       "     n_components=5, n_mix=3,\n",
       "     startprob=array([  4.99779e-02,   1.00000e-01,   1.84038e-01,   1.11027e-17,\n",
       "          6.65983e-01]),\n",
       "     startprob_prior=1.0,\n",
       "     transmat=array([[ 0.85779,  0.02328,  0.00262,  0.1075 ,  0.00881],\n",
       "        [ 0.04662,  0.8624 ,  0.00115,  0.08712,  0.00271],\n",
       "        [ 0.00197,  0.00366,  0.77484,  0.07503,  0.1445 ],\n",
       "        [ 0.02747,  0.09469,  0.04811,  0.81458,  0.01515],\n",
       "        [ 0.00192,  0.00123,  0.08607,  0.01279,  0.89799]]),\n",
       "     transmat_prior=1.0, var=3), GMMHMM(cvtype='diag',\n",
       "     gmms=[GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3)],\n",
       "     n_components=5, n_mix=3,\n",
       "     startprob=array([  1.11027e-17,   1.11027e-17,   1.11027e-17,   1.00000e+00,\n",
       "          1.11027e-17]),\n",
       "     startprob_prior=1.0,\n",
       "     transmat=array([[  8.41063e-01,   6.71039e-02,   2.24026e-16,   2.22045e-16,\n",
       "           9.18328e-02],\n",
       "        [  4.01213e-02,   8.37642e-01,   3.77652e-02,   4.30581e-02,\n",
       "           4.14137e-02],\n",
       "        [  2.28524e-16,   1.23925e-01,   8.73759e-01,   2.22045e-16,\n",
       "           2.31592e-03],\n",
       "        [  2.22146e-16,   2.20772e-02,   2.49302e-16,   9.77923e-01,\n",
       "           2.22057e-16],\n",
       "        [  3.05552e-02,   4.38461e-03,   8.96524e-02,   2.22045e-16,\n",
       "           8.75408e-01]]),\n",
       "     transmat_prior=1.0, var=3), GMMHMM(cvtype='diag',\n",
       "     gmms=[GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3)],\n",
       "     n_components=5, n_mix=3,\n",
       "     startprob=array([  1.11027e-17,   2.52599e-01,   1.11027e-17,   1.38330e-17,\n",
       "          7.47401e-01]),\n",
       "     startprob_prior=1.0,\n",
       "     transmat=array([[  8.56525e-01,   2.26245e-16,   5.36872e-16,   1.43475e-01,\n",
       "           2.22130e-16],\n",
       "        [  2.22122e-16,   8.58560e-01,   5.61753e-03,   2.96333e-02,\n",
       "           1.06189e-01],\n",
       "        [  1.16352e-02,   1.13835e-03,   9.47167e-01,   3.89233e-02,\n",
       "           1.13647e-03],\n",
       "        [  5.17707e-02,   7.72370e-03,   4.39801e-02,   8.66112e-01,\n",
       "           3.04132e-02],\n",
       "        [  2.22058e-16,   1.09134e-01,   1.31901e-03,   8.77118e-03,\n",
       "           8.80776e-01]]),\n",
       "     transmat_prior=1.0, var=3), GMMHMM(cvtype='diag',\n",
       "     gmms=[GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3), GMM(cvtype='diag', n_components=3)],\n",
       "     n_components=5, n_mix=3,\n",
       "     startprob=array([  1.11027e-17,   1.12096e-17,   9.33576e-01,   1.11027e-17,\n",
       "          6.64243e-02]),\n",
       "     startprob_prior=1.0,\n",
       "     transmat=array([[  8.46855e-01,   1.42227e-01,   2.22045e-16,   1.09186e-02,\n",
       "           5.19040e-16],\n",
       "        [  2.82240e-02,   9.14755e-01,   1.26358e-02,   1.85405e-02,\n",
       "           2.58446e-02],\n",
       "        [  6.27129e-03,   1.86167e-02,   9.66666e-01,   2.28537e-16,\n",
       "           8.44647e-03],\n",
       "        [  1.34602e-02,   8.03662e-03,   2.22048e-16,   9.02935e-01,\n",
       "           7.55682e-02],\n",
       "        [  2.27236e-16,   2.31434e-02,   9.19566e-02,   3.09039e-02,\n",
       "           8.53996e-01]]),\n",
       "     transmat_prior=1.0, var=3)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gmm\n",
    "\n",
    "best_models = []\n",
    "\n",
    "def initialize(N):\n",
    "    pi = np.random.rand(N)\n",
    "    pi = pi/np.sum(pi)\n",
    "    A = np.random.rand(N,N)\n",
    "    for i in xrange(len(A)):\n",
    "        A[i] = A[i]/np.sum(A[i])\n",
    "        \n",
    "    return pi, A\n",
    "\n",
    "\n",
    "def problem3():\n",
    "    \n",
    "    test_time = 10\n",
    "    def bio():\n",
    "        #train for biology\n",
    "        \n",
    "        best_log = -np.inf\n",
    "        best_model = None\n",
    "        for i in xrange(test_time):\n",
    "            startprob, transmat = initialize(5)\n",
    "            model = gmmhmm.GMMHMM(n_components=5, n_mix=3, transmat=transmat, startprob= startprob, cvtype='diag')\n",
    "            # these values for covars_prior and var should work well for this problem >>> model.covars_prior = 0.01\n",
    "            model.fit(bio20, init_params='mc', var=0.1)\n",
    "            if model.logprob > best_log:\n",
    "                best_log = model.logprob\n",
    "                best_model = model\n",
    "        \n",
    "        best_models.append(best_model)\n",
    "        \n",
    "        '''startprob, transmat = initialize(5)\n",
    "        #print startprob, transmat\n",
    "        model = gmmhmm.GMMHMM(n_components=5, n_mix=3, transmat=transmat, startprob= startprob, cvtype='diag')\n",
    "        # these values for covars_prior and var should work well for this problem >>> model.covars_prior = 0.01\n",
    "        model.fit(bio20, init_params='mc', var=0.1)\n",
    "        print model.logprob'''\n",
    "    \n",
    "    def stats():\n",
    "        #train for Statistics\n",
    "        best_log = -np.inf\n",
    "        best_model = None\n",
    "        for i in xrange(test_time):\n",
    "            startprob, transmat = initialize(5)\n",
    "            model = gmmhmm.GMMHMM(n_components=5, n_mix=3, transmat=transmat, startprob= startprob, cvtype='diag')\n",
    "            # these values for covars_prior and var should work well for this problem >>> model.covars_prior = 0.01\n",
    "            model.fit(stats20, init_params='mc', var=0.1)\n",
    "            if model.logprob > best_log:\n",
    "                best_log = model.logprob\n",
    "                best_model = model\n",
    "        \n",
    "        best_models.append(best_model)\n",
    "    \n",
    "    def ps():\n",
    "        #train for PoliticalScience\n",
    "        best_log = -np.inf\n",
    "        best_model = None\n",
    "        for i in xrange(test_time):\n",
    "            startprob, transmat = initialize(5)\n",
    "            model = gmmhmm.GMMHMM(n_components=5, n_mix=3, transmat=transmat, startprob= startprob, cvtype='diag')\n",
    "            # these values for covars_prior and var should work well for this problem >>> model.covars_prior = 0.01\n",
    "            model.fit(ps20, init_params='mc', var=0.1)\n",
    "            if model.logprob > best_log:\n",
    "                best_log = model.logprob\n",
    "                best_model = model\n",
    "        \n",
    "        best_models.append(best_model)\n",
    "    \n",
    "    def psych():\n",
    "        #train for Psychology\n",
    "        best_log = -np.inf\n",
    "        best_model = None\n",
    "        for i in xrange(test_time):\n",
    "            startprob, transmat = initialize(5)\n",
    "            model = gmmhmm.GMMHMM(n_components=5, n_mix=3, transmat=transmat, startprob= startprob, cvtype='diag')\n",
    "            # these values for covars_prior and var should work well for this problem >>> model.covars_prior = 0.01\n",
    "            model.fit(psych20, init_params='mc', var=0.1)\n",
    "            if model.logprob > best_log:\n",
    "                best_log = model.logprob\n",
    "                best_model = model\n",
    "        \n",
    "        best_models.append(best_model)\n",
    "\n",
    "    def maths():\n",
    "        #train for Mathematics\n",
    "        best_log = -np.inf\n",
    "        best_model = None\n",
    "        for i in xrange(test_time):\n",
    "            startprob, transmat = initialize(5)\n",
    "            model = gmmhmm.GMMHMM(n_components=5, n_mix=3, transmat=transmat, startprob= startprob, cvtype='diag')\n",
    "            # these values for covars_prior and var should work well for this problem >>> model.covars_prior = 0.01\n",
    "            model.fit(math20, init_params='mc', var=0.1)\n",
    "            if model.logprob > best_log:\n",
    "                best_log = model.logprob\n",
    "                best_model = model\n",
    "        \n",
    "        best_models.append(best_model)\n",
    "    \n",
    "    bio(), stats(), ps(), psych(), maths() #call the above functions\n",
    "    \n",
    "    def print_models():\n",
    "        for i in xrange(len(best_models)):\n",
    "            print best_models[i]\n",
    "    \n",
    "    print_models()\n",
    "    \n",
    "    return best_models #bio() #, stats(), ps(), psych(), maths()\n",
    "    \n",
    "    \n",
    "problem3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = best_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Problem$ $4$\n",
    "\n",
    "Classify the 10 test samples for each word. How does your system perform? Which words are the hardest to correctly classify? Make a dictionary containing the accuracy of the classification of your five testing sets. Specifically, the words/phrases will be the keys, and the values will be the percent accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(best_models,open('best_models.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_models = [bio10,stats10,ps10,psych10,math10]\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in test_models:\n",
    "    for k in i:\n",
    "        best_score = -np.inf\n",
    "        best_model = -1\n",
    "        for j in xrange(len(models)):\n",
    "            score = models[j].score(k)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_model = j\n",
    "        results.append(best_model)\n",
    "    \n",
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PoliticalScience': 90.0, 'Biology': 70.0, 'Statistics': 100.0, 'Psychology': 100.0, 'Mathematics': 100.0}\n",
      "\n",
      " There was average accuracy of  92.0 %\n"
     ]
    }
   ],
   "source": [
    "a,b,c,d,e = 0,0,0,0,0\n",
    "for i in xrange(len(results)):\n",
    "    if results[i] == 0 and i < 11:\n",
    "        a+=1\n",
    "    if results[i] == 1 and 9 < i < 21:\n",
    "        b+=1\n",
    "    if results[i] == 2 and 19 < i < 31:\n",
    "        c+=1\n",
    "    if results[i] == 3 and 29 < i < 41:\n",
    "        d+=1\n",
    "    if results[i] == 4 and 39 < i < 51:\n",
    "        e+=1\n",
    "\n",
    "my_dict = {'Biology':(a/10.)*100, 'Statistics':(b/10.)*100,'PoliticalScience': (c/10.)*100,'Psychology':(d/10.)*100,'Mathematics':(e/10.)*100}\n",
    "\n",
    "print my_dict\n",
    "percent = (my_dict['Biology']+my_dict['Statistics']+my_dict['PoliticalScience']+my_dict['Psychology']+my_dict['Mathematics']) /float(len(my_dict))\n",
    "print \"\\n There was average accuracy of \",percent,\"%\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, there was a 92% overall accuracy and Biology was the most difficult word to determine with a 70% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
