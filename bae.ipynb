{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bae-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "import scipy.stats as st\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gaussian_NB(features, means, variances, prior):\n",
    "    m, n = features.shape\n",
    "    k = len(prior)\n",
    "    stds = np.sqrt(variances)\n",
    "    logprobs = np.zeros((m,k))\n",
    "    logprobs += np.log(prior)\n",
    "    for i in xrange(m):\n",
    "        for j in xrange(k):\n",
    "            for l in xrange(n):\n",
    "                logprobs[i,j] += st.norm.logpdf(features[i,l], loc=means[l,j], scale=stds[l,j])\n",
    "    return logprobs.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contains parts of Problem 1 and 2 below\n",
    "\n",
    "### Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95\n",
      "The SKLearn library got the same thing.\n"
     ]
    }
   ],
   "source": [
    "def seeds():\n",
    "    data = pd.read_csv(\"seeds_dataset.txt\",  delim_whitespace=True, names=\n",
    "            \"Area, Perimeter, Compactness, Length, Width, Asymmetry Coefficient, Groove Length, Class\".split(\", \"))\n",
    "    \n",
    "    #test and train data\n",
    "    test = data.loc[np.random.choice(data.index,40, replace=False)]\n",
    "    train = data.loc[[i for i in set.difference(set(data.index), set(test.index))]]\n",
    "    \n",
    "    #calculate means and variances\n",
    "    means = np.zeros((7,3))\n",
    "    variances = np.zeros((7,3))\n",
    "    for i in xrange(3):\n",
    "        means[:,i] = np.array(train[train[\"Class\"]==i+1].mean())[:-1]\n",
    "        variances[:,i] = np.array(train[train[\"Class\"]==i+1].var())[:-1]\n",
    "        \n",
    "    prior = np.ones(3)/3.\n",
    "    labels = Gaussian_NB(np.array(test)[:,:-1], means, variances, prior) + 1\n",
    "    truth = np.array(test)[:,-1]\n",
    "    \n",
    "    print \"Accuracy:\", (labels==truth).sum()/float(len(labels))\n",
    "    nb = GaussianNB()\n",
    "    nb.fit(np.array(train)[:,:-1], np.array(train)[:,-1])\n",
    "    labels2 = nb.predict(np.array(test)[:,:-1])\n",
    "    \n",
    "    #check to see if same as sklearn\n",
    "    if np.allclose(labels, labels2) == True:\n",
    "        print \"The SKLearn library got the same thing.\"\n",
    "    else:\n",
    "        print \"Didn't get the same thing\"\n",
    "seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class naiveBayes(object):\n",
    "    \"\"\"\n",
    "    This class performs naive bayes classification for word-count document features.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize a naive Bayes classifier.\n",
    "        \"\"\"\n",
    "        self.n_samples, self.n_features, self.class_probs, self.n_classes, self.word_class_probs = [None]*5\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        \"\"\"\n",
    "        Fit the parameters according to the labeled training data (X,Y).\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy arrary of shape [n_samples, n_features].\n",
    "            Each row is essentially the \"word-count\" vector for one of the \"documents\".\n",
    "        Y : numpy array of shape [n_samples].\n",
    "            Gives the class label for each instance of training data. Assume class labels\n",
    "            are {0,1,...,k-1} where k is the number of classes.\n",
    "        \"\"\"\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        self.class_probs = np.array([(Y==i).sum() for i in set(Y)])/float(self.n_samples)\n",
    "        self.n_classes = len(self.class_probs)\n",
    "        self.word_class_probs = np.empty([self.n_classes,self.n_features])\n",
    "        for c in xrange(self.n_classes):\n",
    "            self.word_class_probs[c,:] = (X[Y==c].sum(axis=0)+1).T\n",
    "            self.word_class_probs[c,:] /= self.word_class_probs[c,:].sum()\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class labels of a set of test data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array of shape [n_samples, n_features]\n",
    "        Returns\n",
    "        -------\n",
    "        Y : numpy array of shape [n_samples].\n",
    "            Gives the classification of each row in X\n",
    "        \"\"\"\n",
    "        return np.argmax(np.log(self.class_probs) + X.dot(np.log(self.word_class_probs).T), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95\n",
      "0.95\n",
      "They are the same.\n"
     ]
    }
   ],
   "source": [
    "def spam():\n",
    "    dat = np.loadtxt(\"SpamFeatures.txt\")\n",
    "    labs = np.loadtxt(\"SpamLabels.txt\")\n",
    "    nb = naiveBayes()\n",
    "    \n",
    "    test_rows = np.random.choice(np.arange(len(labs)),500, replace=False)\n",
    "    train_rows = np.array([i for i in xrange(len(labs)) if i not in test_rows])\n",
    "    nb.fit(dat[train_rows], labs[train_rows])\n",
    "    new_labs = nb.predict(dat[test_rows])\n",
    "    \n",
    "    print (new_labs==labs[test_rows]).sum()/float(len(new_labs))\n",
    "    mnb = MultinomialNB()\n",
    "    mnb.fit(dat[train_rows], labs[train_rows])\n",
    "    new_labs2 = mnb.predict(dat[test_rows])\n",
    "    \n",
    "    print (new_labs2 == labs[test_rows]).sum()/float(len(new_labs))\n",
    "    \n",
    "    if np.allclose((new_labs==labs[test_rows]).sum()/float(len(new_labs)),(new_labs2 == labs[test_rows]).sum()/float(len(new_labs))) == True:\n",
    "        print \"They are the same.\"\n",
    "    \n",
    "    \n",
    "spam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
